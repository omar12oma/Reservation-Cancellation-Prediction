{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('editing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>...</th>\n",
       "      <th>market_segment_type_0</th>\n",
       "      <th>market_segment_type_1</th>\n",
       "      <th>market_segment_type_2</th>\n",
       "      <th>market_segment_type_3</th>\n",
       "      <th>market_segment_type_4</th>\n",
       "      <th>has_children</th>\n",
       "      <th>co1</th>\n",
       "      <th>co2</th>\n",
       "      <th>co3</th>\n",
       "      <th>co4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0             2               0                     1                  4   \n",
       "1             2               1                     0                  2   \n",
       "2             1               0                     1                  5   \n",
       "3             1               0                     2                  4   \n",
       "4             2               0                     0                  4   \n",
       "\n",
       "   required_car_parking_space  lead_time  arrival_year  arrival_month  \\\n",
       "0                           0        118          2017             12   \n",
       "1                           0         17          2018              4   \n",
       "2                           0        349          2018             10   \n",
       "3                           0         69          2018              6   \n",
       "4                           0         11          2018              1   \n",
       "\n",
       "   arrival_date  repeated_guest  ...  market_segment_type_0  \\\n",
       "0            28               0  ...                      0   \n",
       "1            14               0  ...                      0   \n",
       "2             4               0  ...                      1   \n",
       "3            12               0  ...                      1   \n",
       "4            20               0  ...                      0   \n",
       "\n",
       "   market_segment_type_1  market_segment_type_2  market_segment_type_3  \\\n",
       "0                      1                      0                      0   \n",
       "1                      1                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      1                      0                      0   \n",
       "\n",
       "   market_segment_type_4  has_children  co1  co2  co3  co4  \n",
       "0                      0             0    0    0    0    1  \n",
       "1                      0             1    0    1    0    0  \n",
       "2                      0             0    0    0    0    1  \n",
       "3                      0             0    0    1    0    0  \n",
       "4                      0             0    1    0    0    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10519,), (3507,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(columns=['booking_status'])\n",
    "y=df['booking_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "y_train.shape ,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of cancel in train set 0.2905219127293469\n",
      "Percentage of cancel in test set 0.2968349016253208\n"
     ]
    }
   ],
   "source": [
    "NOcanceled =y_train.sum()\n",
    "total=y_train.shape[0]\n",
    "print('Percentage of cancel in train set',NOcanceled/total)\n",
    "NOcanceled =y_test.sum()\n",
    "total=y_test.shape[0]\n",
    "print('Percentage of cancel in test set',NOcanceled/total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have outlliers in our data set but we think it is acceptable because there some event the price of hotel ancreased and You must book very early before you arrive Although we well tray modeling in both data with outlier and without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainOut=X_train.copy()\n",
    "y_trainOut=y_train.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10519, 35), (9770, 35), (10519,), (9770,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_outliers(x,y,column):\n",
    "    Q1 = x[column].quantile(0.25)\n",
    "    Q3 = x[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "    y=y[(x[column] >= lower_bound) & (x[column] <= upper_bound)]\n",
    "    x=x[(x[column] >= lower_bound) & (x[column] <= upper_bound)]\n",
    "    return x,y\n",
    "\n",
    "for col in ['lead_time','avg_price_per_room']:\n",
    "    \n",
    "    X_trainOut ,y_trainOut= remove_outliers(X_trainOut,y_trainOut,col)\n",
    "    \n",
    "X_train.shape, X_trainOut.shape,y_train.shape, y_trainOut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of cancel in train set without outlier 0.2804503582395087\n"
     ]
    }
   ],
   "source": [
    "NOcanceled =y_trainOut.sum()\n",
    "total=y_trainOut.shape[0]\n",
    "print('Percentage of cancel in train set without outlier',NOcanceled/total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see hear the Percentage of cancel after removing the outliers decreased Which is expected to affect the model negatively"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMARS\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_trainOut = scaler.fit_transform(X_trainOut)\n",
    "X_testOut = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's start building different models for both data with outliers and without"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8069208099629243\n",
      "test accuracy: 0.8006843455945253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMARS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log=LogisticRegression()\n",
    "log.fit(X_train,y_train)\n",
    "yd=log.predict(X_train)\n",
    "print('train accuracy:',accuracy_score(yd,y_train))\n",
    "yed=log.predict(X_test)\n",
    "print('test accuracy:',accuracy_score(yed,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8056294779938588\n",
      "test accuracy: 0.7031650983746792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMARS\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log=LogisticRegression()\n",
    "log.fit(X_trainOut,y_trainOut)\n",
    "yd=log.predict(X_trainOut)\n",
    "print('train accuracy:',accuracy_score(yd,y_trainOut))\n",
    "yed=log.predict(X_testOut)\n",
    "print('test accuracy:',accuracy_score(yed,y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 15}\n",
      "Accuracy on testing data:  0.8511548331907614\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "param_grid = {'max_depth': range(1, 31)}\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy on testing data: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9044585987261147\n",
      "test accuracy: 0.8534359851725121\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300,max_depth=15)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_train)\n",
    "print( 'train accuracy:' ,accuracy_score(y_train, y_pred))\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': 15}\n",
      "Accuracy on testing data:  0.7627601938979185\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "param_grid = {'max_depth': range(1, 31)}\n",
    "\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Accuracy on testing data: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9192425793244626\n",
      "test accuracy: 0.7031650983746792\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300,max_depth=15)\n",
    "rfc.fit(X_trainOut, y_trainOut)\n",
    "y_pred = rfc.predict(X_trainOut)\n",
    "print( 'train accuracy:' ,accuracy_score(y_trainOut, y_pred))\n",
    "y_pred = rfc.predict(X_testOut)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of n_neighbors: {'n_neighbors': 9}\n",
      "Accuracy of KNN classifier with best n_neighbors: 0.799258625605931\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': range(1, 11)}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best value of n_neighbors:\", grid_search.best_params_)\n",
    "\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy of KNN classifier with best n_neighbors:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8342998383876794\n",
      "test accuracy: 0.799258625605931\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_train)\n",
    "print('train accuracy:' ,accuracy_score(y_train, y_pred))\n",
    "y_pred = knn.predict(X_test)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of n_neighbors: {'n_neighbors': 9}\n",
      "Accuracy of KNN classifier with best n_neighbors: 0.6227544910179641\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': range(1, 11)}\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "print(\"Best value of n_neighbors:\", grid_search.best_params_)\n",
    "\n",
    "accuracy = grid_search.score(X_testOut, y_test)\n",
    "print(\"Accuracy of KNN classifier with best n_neighbors:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8425793244626407\n",
      "test accuracy: 0.6227544910179641\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "knn.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "y_pred = knn.predict(X_trainOut)\n",
    "print('train accuracy:' ,accuracy_score(y_trainOut, y_pred))\n",
    "y_pred = knn.predict(X_testOut)\n",
    "print('test accuracy:' ,accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support vector machine (poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree =  2\n",
      "train accuracy: 0.815381690274741\n",
      "test accuracy: 0.8058169375534645\n",
      "degree =  3\n",
      "train accuracy: 0.8179484741895617\n",
      "test accuracy: 0.8092386655260907\n",
      "degree =  4\n",
      "train accuracy: 0.8240327027283962\n",
      "test accuracy: 0.8118049615055604\n",
      "degree =  5\n",
      "train accuracy: 0.8319231866146972\n",
      "test accuracy: 0.8166524094667807\n",
      "degree =  6\n",
      "train accuracy: 0.8393383401464017\n",
      "test accuracy: 0.8160821214713431\n",
      "degree =  7\n",
      "train accuracy: 0.8460880311816713\n",
      "test accuracy: 0.8163672654690619\n",
      "degree =  8\n",
      "train accuracy: 0.8505561365148778\n",
      "test accuracy: 0.8177929854576561\n",
      "degree =  9\n",
      "train accuracy: 0.8548341097062458\n",
      "test accuracy: 0.8166524094667807\n",
      "degree =  10\n",
      "train accuracy: 0.8607282061032417\n",
      "test accuracy: 0.8157969774736242\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,11):\n",
    "    svmc = SVC(kernel='poly',degree=i)\n",
    "    svmc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svmc.predict(X_train)\n",
    "    print('degree = ',i)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    print('train accuracy:' ,accuracy)\n",
    "\n",
    "    y_pred = svmc.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('test accuracy:' ,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree =  2\n",
      "train accuracy: 0.8165813715455476\n",
      "test accuracy: 0.7031650983746792\n",
      "degree =  3\n",
      "train accuracy: 0.8204708290685773\n",
      "test accuracy: 0.2968349016253208\n",
      "degree =  4\n",
      "train accuracy: 0.8295803480040942\n",
      "test accuracy: 0.7031650983746792\n",
      "degree =  5\n",
      "train accuracy: 0.8363357215967246\n",
      "test accuracy: 0.2968349016253208\n",
      "degree =  6\n",
      "train accuracy: 0.8441146366427841\n",
      "test accuracy: 0.7031650983746792\n",
      "degree =  7\n",
      "train accuracy: 0.8506653019447288\n",
      "test accuracy: 0.2968349016253208\n",
      "degree =  8\n",
      "train accuracy: 0.8569089048106449\n",
      "test accuracy: 0.7031650983746792\n",
      "degree =  9\n",
      "train accuracy: 0.8623336745138178\n",
      "test accuracy: 0.2968349016253208\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "    svmc = SVC(kernel='poly',degree=i)\n",
    "    svmc.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "    y_pred = svmc.predict(X_trainOut)\n",
    "    print('degree = ',i)\n",
    "    accuracy = accuracy_score(y_trainOut, y_pred)\n",
    "    print('train accuracy:' ,accuracy)\n",
    "\n",
    "    y_pred = svmc.predict(X_testOut)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('test accuracy:' ,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 9}\n",
      "Accuracy of Gradient Boosting Classifier with best parameters: 0.8545765611633875\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100,random_state=40)\n",
    "\n",
    "param_grid = {'learning_rate': [0.1],'max_depth':range(2, 10), 'max_features':range(4, 12)}\n",
    "grid_search = GridSearchCV(gb_clf, param_grid, cv=5, scoring='accuracy',verbose=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Accuracy of Gradient Boosting Classifier with best parameters:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9360205342713186\n",
      "test accuracy: 0.8545765611633875\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=9, max_depth=6, random_state=40)\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb_clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print('train accuracy:' ,accuracy) \n",
    "\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('test accuracy:' ,accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'max_features': 11}\n",
      "Accuracy of Gradient Boosting Classifier with best parameters: 0.7031650983746792\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100,random_state=40)\n",
    "\n",
    "param_grid = {'learning_rate': [0.1],'max_depth':range(2, 10), 'max_features':range(4, 12)}\n",
    "grid_search = GridSearchCV(gb_clf, param_grid, cv=5, scoring='accuracy',verbose=0)\n",
    "grid_search.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "accuracy = grid_search.score(X_testOut, y_test)\n",
    "print(\"Accuracy of Gradient Boosting Classifier with best parameters:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8831115660184238\n",
      "test accuracy: 0.7031650983746792\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=11, max_depth=6, random_state=40)\n",
    "\n",
    "gb_clf.fit(X_trainOut, y_trainOut)\n",
    "\n",
    "y_pred = gb_clf.predict(X_trainOut)\n",
    "accuracy = accuracy_score(y_trainOut, y_pred)\n",
    "print('train accuracy:' ,accuracy) \n",
    "\n",
    "y_pred = gb_clf.predict(X_testOut)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('test accuracy:' ,accuracy) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_X_train , X_val , partial_y_train , y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',input_dim=partial_X_train.shape[1]))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', patience=30, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 0.6123 - accuracy: 0.7031 - val_loss: 0.5803 - val_accuracy: 0.7106\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7092 - val_loss: 0.5459 - val_accuracy: 0.7106\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7133 - val_loss: 0.5160 - val_accuracy: 0.7191\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7409 - val_loss: 0.4895 - val_accuracy: 0.7581\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7611 - val_loss: 0.4672 - val_accuracy: 0.7856\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7754 - val_loss: 0.4519 - val_accuracy: 0.8009\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7813 - val_loss: 0.4361 - val_accuracy: 0.7942\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4263 - val_accuracy: 0.8037\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7876 - val_loss: 0.4171 - val_accuracy: 0.8013\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7913 - val_loss: 0.4187 - val_accuracy: 0.8123\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7932 - val_loss: 0.4104 - val_accuracy: 0.8018\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8008 - val_loss: 0.4197 - val_accuracy: 0.7999\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7967 - val_loss: 0.4037 - val_accuracy: 0.8123\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8011 - val_loss: 0.4128 - val_accuracy: 0.8066\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8013 - val_loss: 0.4000 - val_accuracy: 0.8085\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4191 - accuracy: 0.8011 - val_loss: 0.4017 - val_accuracy: 0.8085\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8002 - val_loss: 0.4089 - val_accuracy: 0.8066\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8027 - val_loss: 0.3980 - val_accuracy: 0.8118\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8020 - val_loss: 0.4023 - val_accuracy: 0.8085\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8040 - val_loss: 0.4032 - val_accuracy: 0.8180\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8048 - val_loss: 0.4021 - val_accuracy: 0.8199\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8078 - val_loss: 0.3987 - val_accuracy: 0.8165\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8012 - val_loss: 0.4043 - val_accuracy: 0.8089\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8062 - val_loss: 0.3934 - val_accuracy: 0.8137\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8057 - val_loss: 0.4033 - val_accuracy: 0.8099\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8069 - val_loss: 0.3931 - val_accuracy: 0.8146\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8084 - val_loss: 0.3940 - val_accuracy: 0.8132\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8052 - val_loss: 0.3941 - val_accuracy: 0.8189\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8063 - val_loss: 0.4207 - val_accuracy: 0.7975\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8096 - val_loss: 0.3910 - val_accuracy: 0.8151\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8072 - val_loss: 0.3903 - val_accuracy: 0.8194\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8090 - val_loss: 0.3926 - val_accuracy: 0.8208\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8072 - val_loss: 0.3934 - val_accuracy: 0.8137\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8083 - val_loss: 0.3915 - val_accuracy: 0.8151\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8077 - val_loss: 0.3892 - val_accuracy: 0.8213\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8097 - val_loss: 0.3987 - val_accuracy: 0.8075\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8120 - val_loss: 0.3881 - val_accuracy: 0.8241\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8099 - val_loss: 0.3886 - val_accuracy: 0.8189\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8107 - val_loss: 0.3981 - val_accuracy: 0.8113\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8130 - val_loss: 0.4024 - val_accuracy: 0.8118\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8100 - val_loss: 0.3929 - val_accuracy: 0.8127\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8159 - val_loss: 0.3887 - val_accuracy: 0.8165\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8140 - val_loss: 0.4015 - val_accuracy: 0.8113\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8121 - val_loss: 0.4080 - val_accuracy: 0.8118\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8143 - val_loss: 0.3877 - val_accuracy: 0.8199\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8122 - val_loss: 0.3962 - val_accuracy: 0.8127\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8156 - val_loss: 0.3867 - val_accuracy: 0.8175\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3916 - accuracy: 0.8120 - val_loss: 0.3875 - val_accuracy: 0.8180\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8157 - val_loss: 0.3991 - val_accuracy: 0.8132\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8113 - val_loss: 0.3927 - val_accuracy: 0.8137\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8164 - val_loss: 0.3949 - val_accuracy: 0.8156\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8139 - val_loss: 0.3830 - val_accuracy: 0.8189\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8152 - val_loss: 0.3834 - val_accuracy: 0.8203\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8134 - val_loss: 0.3954 - val_accuracy: 0.8132\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3884 - accuracy: 0.8164 - val_loss: 0.3906 - val_accuracy: 0.8189\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8193 - val_loss: 0.3861 - val_accuracy: 0.8199\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8206 - val_loss: 0.3813 - val_accuracy: 0.8227\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8133 - val_loss: 0.3810 - val_accuracy: 0.8203\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8177 - val_loss: 0.3801 - val_accuracy: 0.8227\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8213 - val_loss: 0.3858 - val_accuracy: 0.8180\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8162 - val_loss: 0.3835 - val_accuracy: 0.8194\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8151 - val_loss: 0.3802 - val_accuracy: 0.8232\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8213 - val_loss: 0.3817 - val_accuracy: 0.8199\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8181 - val_loss: 0.3891 - val_accuracy: 0.8156\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8201 - val_loss: 0.3855 - val_accuracy: 0.8222\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8190 - val_loss: 0.3904 - val_accuracy: 0.8175\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8221 - val_loss: 0.3795 - val_accuracy: 0.8251\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8217 - val_loss: 0.3834 - val_accuracy: 0.8180\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8190 - val_loss: 0.3811 - val_accuracy: 0.8222\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8222 - val_loss: 0.3788 - val_accuracy: 0.8208\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8212 - val_loss: 0.3941 - val_accuracy: 0.8170\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8206 - val_loss: 0.3791 - val_accuracy: 0.8218\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8222 - val_loss: 0.4014 - val_accuracy: 0.8170\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8242 - val_loss: 0.3817 - val_accuracy: 0.8218\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8204 - val_loss: 0.3786 - val_accuracy: 0.8189\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8246 - val_loss: 0.3987 - val_accuracy: 0.8132\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8229 - val_loss: 0.4193 - val_accuracy: 0.8013\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8223 - val_loss: 0.3781 - val_accuracy: 0.8218\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8194 - val_loss: 0.3799 - val_accuracy: 0.8184\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8222 - val_loss: 0.3903 - val_accuracy: 0.8180\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8231 - val_loss: 0.3876 - val_accuracy: 0.8203\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8272 - val_loss: 0.3790 - val_accuracy: 0.8203\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8232 - val_loss: 0.3800 - val_accuracy: 0.8241\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8258 - val_loss: 0.3853 - val_accuracy: 0.8194\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8255 - val_loss: 0.3805 - val_accuracy: 0.8203\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8222 - val_loss: 0.3783 - val_accuracy: 0.8227\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8248 - val_loss: 0.3823 - val_accuracy: 0.8232\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8257 - val_loss: 0.3964 - val_accuracy: 0.8146\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8257 - val_loss: 0.3950 - val_accuracy: 0.8142\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8250 - val_loss: 0.3948 - val_accuracy: 0.8137\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8250 - val_loss: 0.3768 - val_accuracy: 0.8208\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8270 - val_loss: 0.3788 - val_accuracy: 0.8189\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8282 - val_loss: 0.4232 - val_accuracy: 0.7942\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8261 - val_loss: 0.3799 - val_accuracy: 0.8222\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8283 - val_loss: 0.3754 - val_accuracy: 0.8260\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8285 - val_loss: 0.4021 - val_accuracy: 0.8151\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8254 - val_loss: 0.3751 - val_accuracy: 0.8260\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8291 - val_loss: 0.3762 - val_accuracy: 0.8237\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8263 - val_loss: 0.3777 - val_accuracy: 0.8165\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3692 - accuracy: 0.8278 - val_loss: 0.3757 - val_accuracy: 0.8199\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8253 - val_loss: 0.4023 - val_accuracy: 0.8142\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8278 - val_loss: 0.3874 - val_accuracy: 0.8265\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8273 - val_loss: 0.3824 - val_accuracy: 0.8265\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8295 - val_loss: 0.3757 - val_accuracy: 0.8232\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8313 - val_loss: 0.3752 - val_accuracy: 0.8246\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8294 - val_loss: 0.3774 - val_accuracy: 0.8241\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8254 - val_loss: 0.3735 - val_accuracy: 0.8256\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8295 - val_loss: 0.3772 - val_accuracy: 0.8199\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8309 - val_loss: 0.4177 - val_accuracy: 0.8180\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8273 - val_loss: 0.3806 - val_accuracy: 0.8189\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3631 - accuracy: 0.8328 - val_loss: 0.3782 - val_accuracy: 0.8251\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8323 - val_loss: 0.3801 - val_accuracy: 0.8246\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8299 - val_loss: 0.3798 - val_accuracy: 0.8251\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8309 - val_loss: 0.3772 - val_accuracy: 0.8208\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8294 - val_loss: 0.3748 - val_accuracy: 0.8241\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8309 - val_loss: 0.3758 - val_accuracy: 0.8203\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8317 - val_loss: 0.3748 - val_accuracy: 0.8199\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3612 - accuracy: 0.8323 - val_loss: 0.3789 - val_accuracy: 0.8208\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8341 - val_loss: 0.3754 - val_accuracy: 0.8241\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8329 - val_loss: 0.3783 - val_accuracy: 0.8246\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8342 - val_loss: 0.3861 - val_accuracy: 0.8303\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8320 - val_loss: 0.3906 - val_accuracy: 0.8113\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8335 - val_loss: 0.3825 - val_accuracy: 0.8189\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8339 - val_loss: 0.3784 - val_accuracy: 0.8184\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8307 - val_loss: 0.3835 - val_accuracy: 0.8113\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8321 - val_loss: 0.3790 - val_accuracy: 0.8222\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8322 - val_loss: 0.3750 - val_accuracy: 0.8251\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8343 - val_loss: 0.3813 - val_accuracy: 0.8246\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8332 - val_loss: 0.3818 - val_accuracy: 0.8241\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8367 - val_loss: 0.3790 - val_accuracy: 0.8180\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8285 - val_loss: 0.3759 - val_accuracy: 0.8184\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8345 - val_loss: 0.3785 - val_accuracy: 0.8232\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8332 - val_loss: 0.3829 - val_accuracy: 0.8208\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8368 - val_loss: 0.3944 - val_accuracy: 0.8099\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8348 - val_loss: 0.3830 - val_accuracy: 0.8303\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8328 - val_loss: 0.3772 - val_accuracy: 0.8213\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8346 - val_loss: 0.3860 - val_accuracy: 0.8313\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8366 - val_loss: 0.4031 - val_accuracy: 0.8056\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8327 - val_loss: 0.3771 - val_accuracy: 0.8241\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8362 - val_loss: 0.4094 - val_accuracy: 0.8184\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8360 - val_loss: 0.3825 - val_accuracy: 0.8184\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3596 - accuracy: 0.8339 - val_loss: 0.3843 - val_accuracy: 0.8165\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8361 - val_loss: 0.3751 - val_accuracy: 0.8260\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8370 - val_loss: 0.3798 - val_accuracy: 0.8203\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8329 - val_loss: 0.3797 - val_accuracy: 0.8270\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8378 - val_loss: 0.3804 - val_accuracy: 0.8194\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8357 - val_loss: 0.3811 - val_accuracy: 0.8275\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8360 - val_loss: 0.3858 - val_accuracy: 0.8175\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8342 - val_loss: 0.3751 - val_accuracy: 0.8260\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8393 - val_loss: 0.4177 - val_accuracy: 0.8227\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8333 - val_loss: 0.3875 - val_accuracy: 0.8327\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8355 - val_loss: 0.3793 - val_accuracy: 0.8284\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8385 - val_loss: 0.3989 - val_accuracy: 0.8227\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8342 - val_loss: 0.3883 - val_accuracy: 0.8365\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8372 - val_loss: 0.3782 - val_accuracy: 0.8251\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8336 - val_loss: 0.3832 - val_accuracy: 0.8175\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8374 - val_loss: 0.3790 - val_accuracy: 0.8270\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8386 - val_loss: 0.3956 - val_accuracy: 0.8108\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8365 - val_loss: 0.4044 - val_accuracy: 0.8270\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8368 - val_loss: 0.3781 - val_accuracy: 0.8175\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8372 - val_loss: 0.3783 - val_accuracy: 0.8241\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8365 - val_loss: 0.3768 - val_accuracy: 0.8208\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8391 - val_loss: 0.3962 - val_accuracy: 0.8132\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8354 - val_loss: 0.4206 - val_accuracy: 0.7933\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8352 - val_loss: 0.3787 - val_accuracy: 0.8194\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8349 - val_loss: 0.3764 - val_accuracy: 0.8251\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8378 - val_loss: 0.3825 - val_accuracy: 0.8180\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8400 - val_loss: 0.3924 - val_accuracy: 0.8313\n",
      "Epoch 169/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8349 - val_loss: 0.3937 - val_accuracy: 0.8308\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8396 - val_loss: 0.3919 - val_accuracy: 0.8170\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8355 - val_loss: 0.3831 - val_accuracy: 0.8251\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8399 - val_loss: 0.4032 - val_accuracy: 0.8066\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8393 - val_loss: 0.3781 - val_accuracy: 0.8199\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8380 - val_loss: 0.3871 - val_accuracy: 0.8370\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8403 - val_loss: 0.3796 - val_accuracy: 0.8227\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8421 - val_loss: 0.3996 - val_accuracy: 0.8308\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8400 - val_loss: 0.3809 - val_accuracy: 0.8189\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8366 - val_loss: 0.3806 - val_accuracy: 0.8218\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8398 - val_loss: 0.3792 - val_accuracy: 0.8203\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8396 - val_loss: 0.3822 - val_accuracy: 0.8208\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8373 - val_loss: 0.3790 - val_accuracy: 0.8275\n",
      "Epoch 182/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8431 - val_loss: 0.3824 - val_accuracy: 0.8218\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8389 - val_loss: 0.3767 - val_accuracy: 0.8275\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8428 - val_loss: 0.3810 - val_accuracy: 0.8227\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8364 - val_loss: 0.3805 - val_accuracy: 0.8279\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8389 - val_loss: 0.3848 - val_accuracy: 0.8346\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8360 - val_loss: 0.3973 - val_accuracy: 0.8322\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8414 - val_loss: 0.3958 - val_accuracy: 0.8118\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8348 - val_loss: 0.3826 - val_accuracy: 0.8275\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8398 - val_loss: 0.3804 - val_accuracy: 0.8218\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8390 - val_loss: 0.3811 - val_accuracy: 0.8199\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8389 - val_loss: 0.4064 - val_accuracy: 0.8241\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8398 - val_loss: 0.3831 - val_accuracy: 0.8246\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8469 - val_loss: 0.3813 - val_accuracy: 0.8275\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8368 - val_loss: 0.3859 - val_accuracy: 0.8170\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8429 - val_loss: 0.3998 - val_accuracy: 0.8085\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8427 - val_loss: 0.3841 - val_accuracy: 0.8194\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3382 - accuracy: 0.8435 - val_loss: 0.3978 - val_accuracy: 0.8332\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8435 - val_loss: 0.3990 - val_accuracy: 0.8075\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8405 - val_loss: 0.3874 - val_accuracy: 0.8237\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8409 - val_loss: 0.4228 - val_accuracy: 0.8189\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8423 - val_loss: 0.4046 - val_accuracy: 0.8260\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8416 - val_loss: 0.4181 - val_accuracy: 0.8213\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8437 - val_loss: 0.4041 - val_accuracy: 0.8051\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_X_train,partial_y_train, epochs=1000, batch_size=512, callbacks=[es] , validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 1ms/step\n",
      "[1 0 1 ... 1 1 0]\n",
      "(3507,)\n",
      "(3507,)\n",
      "Test Accuracy: 0.8072426575420587\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "accuracy = (y_pred_binary[:,0]== y_test).mean()\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross vlatidion \n",
    "\n",
    "#insamble \n",
    "\n",
    "# Feature Engering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best two models is GradientBoostingClassifier and RandomForestClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.86121673 0.8493346  0.85361217 0.85551331 0.8554446 ]\n",
      "Mean cross-validation score: 0.8550242818063639\n",
      "train accuracy: 0.9245175396900847\n",
      "Test accuracy: 0.8565725691474194\n"
     ]
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier(n_estimators=300, learning_rate=0.1, max_features=9, max_depth=6, random_state=40)\n",
    "clf2 = RandomForestClassifier(n_estimators=300,max_depth=14)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('gb', clf1), ('rf', clf2)], voting='soft')\n",
    "\n",
    "cv_scores = cross_val_score(voting_clf, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"train accuracy:\", accuracy)\n",
    "\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
